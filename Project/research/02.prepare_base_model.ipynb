{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asus/Documents/Chest-Cancer-Classification/Project\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/asus/Documents/Chest-Cancer-Classification/Project'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    params_image_size: list\n",
    "    params_learning_rate: float\n",
    "    params_include_top: bool\n",
    "    params_weights: str\n",
    "    params_classes: int\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cnnClassifier.constants import *\n",
    "from src.cnnClassifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "        config = self.config.prepare_base_model\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        prepare_base_model_config = PrepareBaseModelConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            base_model_path=Path(config.base_model_path),\n",
    "            updated_base_model_path=Path(config.updated_base_model_path),\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_learning_rate=self.params.LEARNING_RATE,\n",
    "            params_include_top=self.params.INCLUDE_TOP,\n",
    "            params_weights=self.params.WEIGHTS,\n",
    "            params_classes=self.params.CLASSES\n",
    "        )\n",
    "\n",
    "        return prepare_base_model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 479.6 MB 37 kB/s  eta 0:00:01     |███████████████▊                | 235.5 MB 3.9 MB/s eta 0:01:03    |██████████████████████████████  | 448.2 MB 1.0 MB/s eta 0:00:31     |██████████████████████████████▋ | 459.2 MB 9.4 MB/s eta 0:00:032 MB 982 kB/s eta 0:00:17\n",
      "\u001b[?25hCollecting typing-extensions<4.6.0,>=3.6.6\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting numpy<=1.24.3,>=1.22\n",
      "  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 4.2 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.66.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.5 MB 152 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.14,>=2.13.1\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/asus/.local/lib/python3.8/site-packages (from tensorflow) (4.25.4)\n",
      "Requirement already satisfied: packaging in /home/asus/.local/lib/python3.8/site-packages (from tensorflow) (23.2)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 4.1 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\"\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting flatbuffers>=23.1.21\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.3 MB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[K     |████████████████████████████████| 440 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[K     |████████████████████████████████| 200 kB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/asus/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/asus/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.7)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/asus/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.4)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/asus/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/asus/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/asus/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (6.11.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/asus/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.5)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/asus/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.20.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.1.0)\n",
      "\u001b[31mERROR: sqlalchemy 2.0.32 has requirement typing-extensions>=4.6.0, but you'll have typing-extensions 4.5.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: typing-extensions, numpy, opt-einsum, wrapt, grpcio, libclang, keras, google-pasta, tensorflow-io-gcs-filesystem, gast, flatbuffers, astunparse, absl-py, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, tensorboard-data-server, requests-oauthlib, google-auth-oauthlib, tensorboard, termcolor, h5py, tensorflow-estimator, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.12.2\n",
      "    Uninstalling typing-extensions-4.12.2:\n",
      "      Successfully uninstalled typing-extensions-4.12.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 cachetools-5.5.0 flatbuffers-24.3.25 gast-0.4.0 google-auth-2.34.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.66.0 h5py-3.11.0 keras-2.13.1 libclang-18.1.1 numpy-1.24.3 opt-einsum-3.3.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 requests-oauthlib-2.0.0 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.4.0 typing-extensions-4.5.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 14:42:29.317860: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-28 14:42:29.379313: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-28 14:42:29.380073: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-28 14:42:30.333057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PrepareBaseModel:\n",
    "    def __init__(self, config: PrepareBaseModelConfig):\n",
    "        self.config = config\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "        \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.applications.vgg19.VGG19(\n",
    "            input_shape=self.config.params_image_size,\n",
    "            weights=self.config.params_weights,\n",
    "            include_top=self.config.params_include_top\n",
    "        )\n",
    "\n",
    "        self.save_model(path=self.config.base_model_path, model=self.model)\n",
    "\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _prepare_full_model(model, classes, freeze_all, freeze_till, learning_rate):\n",
    "        if freeze_all:\n",
    "            for layer in model.layers:\n",
    "                model.trainable = False\n",
    "        elif (freeze_till is not None) and (freeze_till > 0):\n",
    "            for layer in model.layers[:-freeze_till]:\n",
    "                model.trainable = False\n",
    "\n",
    "        flatten_in = tf.keras.layers.Flatten()(model.output)\n",
    "        prediction = tf.keras.layers.Dense(\n",
    "            units=classes,\n",
    "            activation=\"softmax\"\n",
    "        )(flatten_in)\n",
    "\n",
    "        full_model = tf.keras.models.Model(\n",
    "            inputs=model.input,\n",
    "            outputs=prediction\n",
    "        )\n",
    "\n",
    "        full_model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "\n",
    "        full_model.summary()\n",
    "        return full_model\n",
    "    \n",
    "\n",
    "    def update_base_model(self):\n",
    "        self.full_model = self._prepare_full_model(\n",
    "            model=self.model,\n",
    "            classes=self.config.params_classes,\n",
    "            freeze_all=True,\n",
    "            freeze_till=None,\n",
    "            learning_rate=self.config.params_learning_rate\n",
    "        )\n",
    "\n",
    "        self.save_model(path=self.config.updated_base_model_path, model=self.full_model)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-28 14:42:58,484: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-08-28 14:42:58,490: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-08-28 14:42:58,492: INFO: common: created directory at: artifacts]\n",
      "[2024-08-28 14:42:58,494: INFO: common: created directory at: artifacts/prepare_base_model]\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 22s 0us/step\n",
      "[2024-08-28 14:43:21,013: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asus/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20074562 (76.58 MB)\n",
      "Trainable params: 50178 (196.01 KB)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_base_model_config = config.get_prepare_base_model_config()\n",
    "    prepare_base_model = PrepareBaseModel(config=prepare_base_model_config)\n",
    "    prepare_base_model.get_base_model()\n",
    "    prepare_base_model.update_base_model()\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
